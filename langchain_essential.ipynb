{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### Loading the model and testing with the simple message"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.messages import HumanMessage, AIMessage, SystemMessage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_google_genai import ChatGoogleGenerativeAI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = ChatGoogleGenerativeAI(model=\"gemini-pro\",temperature=0.7, convert_system_message_to_human=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "message = [SystemMessage(content=\"Hi you are a nice bot\"),HumanMessage(content=\"Hi i am Asif\")]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "response_1 = model.invoke(message)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content=\"Hello Asif, it's nice to meet you. I am happy to assist you with any questions you may have.\", response_metadata={'prompt_feedback': {'block_reason': 0, 'safety_ratings': []}, 'finish_reason': 'STOP', 'safety_ratings': [{'category': 'HARM_CATEGORY_SEXUALLY_EXPLICIT', 'probability': 'NEGLIGIBLE', 'blocked': False}, {'category': 'HARM_CATEGORY_HATE_SPEECH', 'probability': 'NEGLIGIBLE', 'blocked': False}, {'category': 'HARM_CATEGORY_HARASSMENT', 'probability': 'NEGLIGIBLE', 'blocked': False}, {'category': 'HARM_CATEGORY_DANGEROUS_CONTENT', 'probability': 'NEGLIGIBLE', 'blocked': False}]}, id='run-a5c5fb9f-bdcc-4cd7-9584-c381d5bc734c-0', usage_metadata={'input_tokens': 12, 'output_tokens': 25, 'total_tokens': 37})"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Hello Asif, it's nice to meet you. I am happy to assist you with any questions you may have.\""
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response_1.content"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Output parser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.output_parsers import StrOutputParser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "parser = StrOutputParser()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Thank you for the compliment. My name is Gemini. I am a multi-modal AI model, developed by Google. I am designed to understand and generate human language, and to answer questions and provide information to the best of my abilities. I am still under development, but I am learning new things every day.\\n\\nIs there anything I can help you with today?'"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "parser.invoke(model.invoke(message))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "message_2 = [SystemMessage(content=\"Hi you are a nice urdu poet\"),HumanMessage(content=\"can you write a poem for kids?\")]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'**چاند تارے**\\n\\nآسماں پر چاند ہے، چمک رہا ہے،\\nتارے جھلمل ہیں، مانو ہنس رہے ہیں۔\\nچاند سورج کا بھائی ہے،\\nتارے اس کے ساتھی ہیں۔\\n\\nچاند تارے سب مل کر،\\nرات کو بناتے ہیں روشن۔\\nبچے سو جائیں جلدی से،\\nچاند تارے کہتے हैं।\\n\\nرات بھر چمکتے رہتے ہیں،\\nصبح ہوتے ہی چھپ جاتے ہیں۔\\nپھر آئیں گے کل رات کو،\\nتمہیں پھر سے خواب دکھائیں گے۔'"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "parser.invoke(model.invoke(message_2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### chaining with LCEL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Hi Asif, it's nice to meet you. I'm Gemini, a multi-modal AI model, developed by Google. I'm designed to assist and provide information to the best of my abilities. Is there anything I can help you with today?\""
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain_1 = model | parser\n",
    "chain_1.invoke(message)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'**بچوں کا نغمہ**\\n\\nہم بچے ہیں چھوٹے چھوٹے\\nکھیلنا ہمارا کام ہے\\nہنستے کھیلتے گاتے ہیں\\nیہی ہمارا کام ہے\\n\\n(کورس)\\nہم ہیں بچے ہم ہیں بچے\\nہماری دنیا ہے رنگین\\nہماری خوشیوں میں کوئی غم نہیں\\nہمارا بچپن ہے سنہریں\\n\\nپڑھنا لکھنا بھی ہم کو آتا ہے\\nپر کھیلنا ہمیں سب سے پیارا ہے\\nگڑیا گھوڑے، پتنگ اڑانا\\nیہی ہے ہمارا شوق سب سے بڑا\\n\\n(کورس)\\nہم ہیں بچے ہم ہیں بچے\\nہماری دنیا ہے رنگین\\nہماری خوشیوں میں کوئی غم نہیں\\nہمارا بچپن ہے سنہریں'"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain_2 = model | parser\n",
    "chain_1.invoke(message_2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prompt templating"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.prompts import ChatPromptTemplate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt_template = ChatPromptTemplate.from_messages([\n",
    "    \"system\",\"translate the following into {language}\",\n",
    "    \"user\",\"{text}\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = prompt_template.invoke({\"language\":\"italian\",\"text\":\"GenAI is the future of tech we must all learn\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "messages=[HumanMessage(content='system'), HumanMessage(content='translate the following into italian'), HumanMessage(content='user'), HumanMessage(content='GenAI is the future of tech we must all learn')]\n"
     ]
    }
   ],
   "source": [
    "print(prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "response = parser.invoke(model.invoke(prompt))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'GenAI è il futuro della tecnologia che tutti dobbiamo imparare'"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt_2= prompt_template.invoke({\"language\":\"german\",\"text\":\"GenAI is the future of tech we must all learn\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'GenAI ist die Zukunft der Technologie, die wir alle erlernen müssen'"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "parser.invoke(model.invoke(prompt_2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Applying chaining(LCEL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "chain_1 = prompt_template | model | parser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'اعظم امیر لوی هلک چټلې واده ته روان دی خو هغه ما ته بلنه نه ده ورکړه ډېره اندېښه ده حال دا چې هغه زه ښه ملګری یم زه نه پوهیږم ولې هغه ما ته پام نه دی ورکړی واقعاً ما ته دا نه ښکاري'"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain_1.invoke({\"language\":\"pashto\",\"text\":\"Aamir the great boy gonna get to married soon but he did not invite me so sad although he is my good friend i dont understand why he ignore me, i dont like this really\"})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Agents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langgraph.checkpoint.memory import MemorySaver\n",
    "from langgraph.prebuilt import create_react_agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.tools.tavily_search import TavilySearchResults\n",
    "from langchain_core.messages import HumanMessage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [],
   "source": [
    "memory = MemorySaver()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [],
   "source": [
    "search = TavilySearchResults(max_results=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "tools = [search]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Key 'title' is not supported in schema, ignoring\n",
      "Key 'title' is not supported in schema, ignoring\n"
     ]
    }
   ],
   "source": [
    "agent_executor = create_react_agent(model,tools,checkpointer=memory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = {\"configurable\":{\"thread_id\": \"abc130\"}}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'agent': {'messages': [AIMessage(content='', additional_kwargs={'function_call': {'name': 'tavilly_search_results_json', 'arguments': '{\"query\": \"Is Gilgit Baltistan, Pakistan a province?\"}'}}, response_metadata={'prompt_feedback': {'block_reason': 0, 'safety_ratings': []}, 'finish_reason': 'STOP', 'safety_ratings': [{'category': 'HARM_CATEGORY_SEXUALLY_EXPLICIT', 'probability': 'NEGLIGIBLE', 'blocked': False}, {'category': 'HARM_CATEGORY_DANGEROUS_CONTENT', 'probability': 'NEGLIGIBLE', 'blocked': False}, {'category': 'HARM_CATEGORY_HATE_SPEECH', 'probability': 'NEGLIGIBLE', 'blocked': False}, {'category': 'HARM_CATEGORY_HARASSMENT', 'probability': 'NEGLIGIBLE', 'blocked': False}]}, id='run-f67a5e99-fd08-454c-8bad-d92c415cceac-0', tool_calls=[{'name': 'tavilly_search_results_json', 'args': {'query': 'Is Gilgit Baltistan, Pakistan a province?'}, 'id': '2c56fbe2-f5b5-4252-b59b-495335cf6c75', 'type': 'tool_call'}], usage_metadata={'input_tokens': 202, 'output_tokens': 31, 'total_tokens': 233})]}}\n",
      "{'tools': {'messages': [ToolMessage(content='Error: tavilly_search_results_json is not a valid tool, try one of [tavily_search_results_json].', name='tavilly_search_results_json', tool_call_id='2c56fbe2-f5b5-4252-b59b-495335cf6c75')]}}\n",
      "{'agent': {'messages': [AIMessage(content='I am sorry, I cannot fulfill this request. The available tools lack the desired functionality.', response_metadata={'prompt_feedback': {'block_reason': 0, 'safety_ratings': []}, 'finish_reason': 'STOP', 'safety_ratings': [{'category': 'HARM_CATEGORY_SEXUALLY_EXPLICIT', 'probability': 'NEGLIGIBLE', 'blocked': False}, {'category': 'HARM_CATEGORY_HATE_SPEECH', 'probability': 'NEGLIGIBLE', 'blocked': False}, {'category': 'HARM_CATEGORY_HARASSMENT', 'probability': 'NEGLIGIBLE', 'blocked': False}, {'category': 'HARM_CATEGORY_DANGEROUS_CONTENT', 'probability': 'NEGLIGIBLE', 'blocked': False}]}, id='run-cdeb537b-54af-493b-bdc3-e43bf64bef80-0', usage_metadata={'input_tokens': 284, 'output_tokens': 18, 'total_tokens': 302})]}}\n"
     ]
    }
   ],
   "source": [
    "for chunk in agent_executor.stream({\"messages\":[HumanMessage(content=\"Hi i am Asif and live in Gilgit baltistan, pakistan\")]},config):\n",
    "    print(chunk)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'agent': {'messages': [AIMessage(content='I do not have access to real-time information and cannot provide you with the weather conditions for your location.', response_metadata={'prompt_feedback': {'block_reason': 0, 'safety_ratings': []}, 'finish_reason': 'STOP', 'safety_ratings': [{'category': 'HARM_CATEGORY_SEXUALLY_EXPLICIT', 'probability': 'NEGLIGIBLE', 'blocked': False}, {'category': 'HARM_CATEGORY_HATE_SPEECH', 'probability': 'NEGLIGIBLE', 'blocked': False}, {'category': 'HARM_CATEGORY_HARASSMENT', 'probability': 'NEGLIGIBLE', 'blocked': False}, {'category': 'HARM_CATEGORY_DANGEROUS_CONTENT', 'probability': 'NEGLIGIBLE', 'blocked': False}]}, id='run-8677a082-9a55-458e-bc76-d914874683fa-0', usage_metadata={'input_tokens': 203, 'output_tokens': 22, 'total_tokens': 225})]}}\n"
     ]
    }
   ],
   "source": [
    "for chunk in agent_executor.stream({\"messages\":[HumanMessage(content=\"Can you tell me the weather where i live?\")]},config=config):\n",
    "    print(chunk)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
